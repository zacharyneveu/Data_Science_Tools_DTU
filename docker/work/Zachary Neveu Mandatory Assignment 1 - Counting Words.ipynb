{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory Assignment 1: Counting Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Zachary Neveu (s191344)* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the first of three mandatory assignments to be handed in as part of the assessment for the course 02807 Computational Tools for Data Science at Technical University of Denmark, autumn 2019.**\n",
    "\n",
    "#### Practical info\n",
    "- **The assignment is to be done individually. You are under no circumstances allowed to collaborate with anyone on solving the exercises (cf. the full policy on this on the course website)**\n",
    "- **You must hand in one Jupyter notebook (this notebook) with your solution**\n",
    "- **The hand-in of the notebook is due 2019-10-10, 23:59 on DTU Inside**\n",
    "\n",
    "#### Your solution\n",
    "- **Your solution should be in Python**\n",
    "- **For each question you should use exactly the cells provided for your solution**\n",
    "- **You should not remove the problem statements, and you should not modify the structure of the notebook**\n",
    "- **Your notebook should be runnable, i.e., clicking [>>] in Jupyter should generate the result that you want to be assessed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction\n",
    "In this assignment you will build data structures for counting words in a text. Suppose you are given a very large corpus of text, and from time to time you need to count how many times a word occurs. You could write a program that searches the text from start to end every time you want to make a query, but for large texts, this will be very slow. A common way to handle this, is to preprocess the text into a data structure that contains exactly the information needed to answer specific queries like the frequency of a word.\n",
    "\n",
    "Given a text, you should build data structures that can answer the following questions efficiently:\n",
    "- How many times does a given word occur in the text? (exercise 2)\n",
    "- How many times in total does a word starting with a given prefix occur? (exercise 3)\n",
    "\n",
    "For each of these questions you should write a function that organizes data in a way (the data structure) that makes it possible to write an efficient function (the query) to answer the questions. A good data structure is one where the query is much faster than just searching the text while still is not using too much space.\n",
    "\n",
    "You should not use any Python libraries (except `string`!) to solve the exercises. You may use build-ins like lists, dictionaries, `map`, `filter`, and so on.\n",
    "\n",
    "You should provide implementations for the functions in this notebook. Do not change the names of the functions.\n",
    "\n",
    "To test your programs, we will use the complete works of William Shakespeare. Please run the cells below to load the text and show a preview. You should be online before you do this. Note that a good solution will have to work for even larger texts than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "text = requests.get('https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the 100th Etext file presented by Project Gutenberg, and\n",
      "is presented in cooperation with World Library, Inc., from their\n",
      "Library of the Future and Shakespeare CDROMS.  Project Gutenberg\n",
      "often releases Etexts that are NOT placed in the Public Domain!!\n",
      "\n",
      "Shakespeare\n",
      "\n",
      "*This Etext has certain copyright implications you should read!*\n",
      "\n",
      "<<THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM\n",
      "SHAKESPEARE IS COPYRIGHT 1990-1993 BY WORLD LIBRARY, INC., AND IS\n",
      "PROVIDED BY PROJECT GUTENBERG ETEXT OF ILLINOIS BENEDICTINE COLLEGE\n",
      "WITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE\n",
      "DISTRIBUTED SO LONG AS SUCH COPIES (1) ARE FOR YOUR OR OTHERS\n",
      "PERSONAL USE ONLY, AND (2) ARE NOT DISTRIBUTED OR USED\n",
      "COMMERCIALLY.  PROHIBITED COMMERCIAL DISTRIBUTION INCLUDES BY ANY\n",
      "SERVICE THAT CHARGES FOR DOWNLOAD TIME OR FOR MEMBERSHIP.>>\n",
      "\n",
      "*Project Gutenberg is proud to cooperate with The World Library*\n",
      "in the presentation of The Complete Works of William Shakespeare\n",
      "for your reading for educatio ...\n"
     ]
    }
   ],
   "source": [
    "print('{} ...'.format(text[0:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 1\n",
    "In this exercise you should create a helper function for parsing a text into an iterable (e.g., a list) of words. You will need this in the subsequent exercises.\n",
    "\n",
    "You should make sure that:\n",
    "- each element of the iterable is exactly one word,\n",
    "- all words are lower case,\n",
    "- words do not contain punctuation.\n",
    "\n",
    "Write a function `text_to_words()` that takes as input a string and output an iterable of the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_words(text): return text.lower().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should implement this!\n",
    "def text_to_words(text):\n",
    "    #table = str.maketrans(string.punctuation, \" \"*len(string.punctuation))\n",
    "    t = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return t.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this` `is` `a` `test'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should output 'this is a test'\n",
    "'` `'.join(text_to_words('THIS is, a test!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text_to_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900987"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 2\n",
    "In this exercise you should create a data structure that can give an answer to the following query.\n",
    "- How many times does a given word occur in the text?\n",
    "\n",
    "You should do the following:\n",
    "- Write a function `build_word_count_data_structure()` that takes as input an iterable of strings, and outputs a data structure for looking up how many times a string occurs.\n",
    "\n",
    "- Write a function `get_word_count()` that uses your data structure to count the number of times a word occurs.\n",
    "\n",
    "- Explain with words how your data is organized in your data structure, how your function constructs it, and how a query works. Why is it efficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should implement this!\n",
    "def build_word_count_data_structure(words):\n",
    "    counts = {}\n",
    "    for w in words:\n",
    "        try:\n",
    "            counts[w] += 1\n",
    "        except:\n",
    "            counts[w] = 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = build_word_count_data_structure(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should implement this!\n",
    "def get_word_count(ds, word):\n",
    "    return ds[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_word_count(ds, 'romeo') == sum([1 for w in words if w=='romeo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "A dictionary is a very simple structure that maps between keys and values. Using words as keys and counts as values allows for an $O(1)$ runtime to get the count for a word. Creating the dictionary takes $O(N)$ time, and the dictionary requires $O(N)$ space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 3\n",
    "In this exercise you should create a data structure that can give an answer to the following query.\n",
    "- How many times in total does a word starting with a given prefix occur?\n",
    "\n",
    "For example, `bar` is a prefix of `bar`, `barracuda`, and `barrier`, and the result of the query should include the sum of the number of times each of those words occur.\n",
    "\n",
    "You should do the following:\n",
    "- Write a function `build_prefix_count_data_structure()` that takes as input a list of strings, and outputs a data structure for looking up how many times a prefix occurs in words.\n",
    "\n",
    "- Write a function `get_prefix_count()` that uses your data structure to count the number of times a prefix occurs.\n",
    "\n",
    "- Explain with words how your data is organized in your data structure, how your function constructs it, and how a query works. Why is it efficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trie:\n",
    "    def __init__(self, words=None, name=''):\n",
    "        self.name = name\n",
    "        self.children = {}\n",
    "        self.nsubs = 0\n",
    "        if words:\n",
    "            for word in words:\n",
    "                self.add(word)\n",
    "        \n",
    "    def add(self, word):\n",
    "        assert word.startswith(self.name)\n",
    "        # First check if this is the final node, if so return\n",
    "        self.nsubs += 1\n",
    "        if word == self.name:\n",
    "            return\n",
    "        if word[:len(self.name)+1] not in self.children: # add child if it doesn't exist\n",
    "            #print(f\"Adding child {word[:len(self.name)+1]}\")\n",
    "            self.children[word[:len(self.name)+1]] = Trie(name=word[:len(self.name)+1])\n",
    "        self.children[word[:len(self.name)+1]].add(word)\n",
    "        \n",
    "    def get_sum(self, word):\n",
    "        if self.name == word:\n",
    "            return self.nsubs\n",
    "        else:\n",
    "            try:\n",
    "                return self.children[word[:len(self.name)+1]].get_sum(word)\n",
    "            except Exception as E:\n",
    "                print(E)\n",
    "                return False\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return f'{self.name} ({self.nsubs} children)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prefix_count_data_structure(words):\n",
    "    return Trie(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prefix_count(trie, prefix):\n",
    "    return trie.get_sum(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Trie(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26840"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.get_sum('and')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing speed with random word times (vs counting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_pre():\n",
    "    pre = random.choice(words)\n",
    "    return pre[:random.randint(1,len(pre))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres = [get_random_pre() for i in range(100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time with Trie datastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 309 µs, sys: 4 µs, total: 313 µs\n",
      "Wall time: 319 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "for pre in pres:\n",
    "    root.get_sum(pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time searching through unique words sums (from part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 350 ms, sys: 3 µs, total: 350 ms\n",
      "Wall time: 348 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for pre in pres:\n",
    "    sum([ds[w] for w in ds.keys() if w.startswith(pre)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time searching from scratch in word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.19 s, sys: 7.63 ms, total: 7.19 s\n",
      "Wall time: 7.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "for pre in pres:\n",
    "    sum([1 for w in words if w.startswith(pre)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "_Explain your data structure with words_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *Trie* is a tree data structure which is quite useful for storing prefix-dictionaries. The key idea behind this data structure is that if you start with the first letter of a word, each letter you add greatly narrows down the number of possible words this could be. Using this property, Using this property, one can construct a tree where all children of a node have that node's value as a prefix. For this specific problem, it is also easy enough to include a count of all descendents of each node. In a Trie, the time needed to search a node as well as the time needed to add a node are proportional to the length of the word $l_w$. This makes the time to get the number of descendents $O(l_w)$. The tradeoff for this fast access time is that creating a Trie takes $O(n_w*l_w)$ time, and $O(n_{wu})$ space, where $n_w$ is the total number of words and $n_{wu}$ is the number of unique words. This tradeoff makes a lot of sense in practice for several reasons. First, the number of unique words is often much smaller than the total number of words (3% of the size in our case). Second, Most words are quite short (see the histogram below). Having an access time that is proportional to the length of a word is then very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03145772358535695"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(words)) / len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trie Example Figure\n",
    "![Trie](https://proxy.duckduckgo.com/iu/?u=https%3A%2F%2Fkoenig-media.raywenderlich.com%2Fuploads%2F2016%2F10%2FSwiftAlgClub_TrieData-trie-1.png&f=1&nofb=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "plt.style.use('Solarize_Light2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency of Word Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdc3c71aad343d2a15ef744b8d490b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([3.89930e+04, 1.50332e+05, 1.91201e+05, 2.04690e+05, 1.11393e+05,\n",
       "        7.26870e+04, 5.72980e+04, 3.49530e+04, 1.98660e+04, 1.12900e+04,\n",
       "        5.00000e+03, 0.00000e+00, 2.05000e+03, 6.69000e+02, 3.64000e+02,\n",
       "        1.27000e+02, 3.10000e+01, 2.00000e+01, 1.10000e+01, 4.00000e+00,\n",
       "        0.00000e+00, 2.00000e+00, 2.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 2.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00]),\n",
       " array([ 1.        ,  1.91428571,  2.82857143,  3.74285714,  4.65714286,\n",
       "         5.57142857,  6.48571429,  7.4       ,  8.31428571,  9.22857143,\n",
       "        10.14285714, 11.05714286, 11.97142857, 12.88571429, 13.8       ,\n",
       "        14.71428571, 15.62857143, 16.54285714, 17.45714286, 18.37142857,\n",
       "        19.28571429, 20.2       , 21.11428571, 22.02857143, 22.94285714,\n",
       "        23.85714286, 24.77142857, 25.68571429, 26.6       , 27.51428571,\n",
       "        28.42857143, 29.34285714, 30.25714286, 31.17142857, 32.08571429,\n",
       "        33.        ]),\n",
       " <a list of 35 Patch objects>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist([len(w) for w in words], 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02d19071b256489eb022fdcc7591d00b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0bef3b56083a416b9edd53e09365efdd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "286a4a3ead9f421da8d7414491b43932": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.4.2",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_c74faac1c629447b99c5336ff99c8ad8",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "314e18852d6949678d2ba5b59cf98421": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4ee6e1bccb15450e9c431d169076cfd7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "723e1c426391430b9c26fdec8eba21dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9e086aee83b142d7abbc88c56c05a085": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.4.2",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_02d19071b256489eb022fdcc7591d00b",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "b09c3dacc5db48b39e92a5cec54d6968": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b3c4392f2f1d4478b2491d3562953e89": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.4.2",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_c5a763e10b504491895e52b47ddbe2bb",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "b92d68cbbb8944fb872ba7093dcf6721": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c5a763e10b504491895e52b47ddbe2bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c74faac1c629447b99c5336ff99c8ad8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cbe6bd82a7834a5e8f5816f493c5ae34": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.4.2",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_723e1c426391430b9c26fdec8eba21dd",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "d0610ba5e6fa4a3997b6b56ba410f6cc": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.4.2",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_0bef3b56083a416b9edd53e09365efdd",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Pan axes with left mouse, zoom with right",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "dc8562a4b25a45d283002e08b68c3c44": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fcdc3c71aad343d2a15ef744b8d490b5": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.4.2",
      "model_name": "MPLCanvasModel",
      "state": {
       "layout": "IPY_MODEL_b92d68cbbb8944fb872ba7093dcf6721",
       "toolbar": "IPY_MODEL_cbe6bd82a7834a5e8f5816f493c5ae34",
       "toolbar_position": "left"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
