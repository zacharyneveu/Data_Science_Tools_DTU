{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed computing\n",
    "Idea: split computational load across 2+ computers (nodes)  \n",
    "Master <-> workers architecture  \n",
    "\n",
    "### Pros\n",
    "1. Speeds up computation\n",
    "2. Spread out the risk of a crash\n",
    "\n",
    "### Cons\n",
    "1. Distributing data is expensive (network bottleneck)\n",
    "2. Synchronization is expensive (disk bottleneck)\n",
    "3. Writing distributed algorithms is difficult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduce Model\n",
    "Both a computational model and a specific tool name\n",
    "\n",
    "Stages:  \n",
    "1. Input\n",
    "2. Split - move part of data to each worker\n",
    "3. Map - apply local transform to data on each node\n",
    "4. Shuffle - Exchange data between nodes as needed\n",
    "5. Reduce - Compute aggrate result of some kind\n",
    "6. Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: counting unique words in document  \n",
    "+ input: document with all words\n",
    "+ split: divide document evenly among nodes\n",
    "+ map: count unique words on each node\n",
    "+ shuffle: group unique words on each node, i.e. first node keeps all counts of word \"car\"\n",
    "+ reduce: take sum of each unique word\n",
    "+ output: dict of word counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In spark: specify map and reduce function and spark will handle the rest.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Cluster for Me?\n",
    "Spark can still be useful for running multi core workloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark\n",
    "+ Written in Scala\n",
    "+ Invented at Berkeley\n",
    "+ Open source via Apache\n",
    "+ Default big-data tool in industry\n",
    "\n",
    "### Features\n",
    "+ Built-in resilience - re-assigns jobs that don't return results\n",
    "+ Node awareness\n",
    "+ Supports tons of file formats/sources\n",
    "+ Streaming\n",
    "+ Many platforms\n",
    "+ high-level api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences from Pandas\n",
    "+ Immutable dataframes\n",
    "+ No random access\n",
    "+ Automatic optimizatioin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Level API\n",
    "2 kinds of operations\n",
    "+ transformation: like torch.view - no computation is done, just add a transform\n",
    "+ action: kicks off computation - applies transforms to data etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "+ Data often goes thgouth many transformations before hitting an action.  \n",
    "+ Spark Catalyst engine optimizes order of operations to be faster - filter as early as possible\n",
    "\n",
    "## No Random Access\n",
    "+ Master knows how large split to each node is, but doesn't remember exactly what data is where\n",
    "+ Can't get a random row off a random node, that would take forever\n",
    "+ Order not guaranteed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SparkIntro\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option('header',True).option('inferSchema',True).csv('data/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|   false|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|    true|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|    true|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|    true|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|   false|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|   false|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|   false|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|   false|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|    true|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|    true|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|    true|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|    true|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|   false|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|   false|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|   false|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|    true|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|   false|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|    true|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|   false|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|    true|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.68 ms, sys: 248 µs, total: 1.93 ms\n",
      "Wall time: 69.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "males = df.filter(f.col('Sex') == 'male')\n",
    "num_males = males.count()\n",
    "num_males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.49 ms, sys: 219 µs, total: 1.71 ms\n",
      "Wall time: 1.18 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "males = pdf[pdf['Sex'] == 'male']\n",
    "males['Sex'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
